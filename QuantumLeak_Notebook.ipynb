{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8465d5b8",
   "metadata": {},
   "source": [
    "\n",
    "# QuantumLeak Project Notebook\n",
    "\n",
    "Đây là phiên bản Jupyter Notebook được tạo tự động từ dự án Python gốc.\n",
    "Notebook này chứa tất cả mã nguồn cần thiết và được cấu trúc để chạy trong các môi trường như Google Colab.\n",
    "\n",
    "**Hướng dẫn:**\n",
    "1.  Chạy các cell theo thứ tự từ trên xuống dưới.\n",
    "2.  Cell đầu tiên sẽ cài đặt tất cả các thư viện cần thiết.\n",
    "3.  Các cell tiếp theo sẽ sử dụng \"magic command\" `%%writefile` để tái tạo lại cấu trúc file của dự án.\n",
    "4.  Cell cuối cùng chứa mã từ `main.py` để bạn có thể chạy các thử nghiệm.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cafd63d",
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install pennylane pennylane-lightning torch torchvision pandas numpy scikit-learn tqdm joblib matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407940ca",
   "metadata": {},
   "source": [
    "\n",
    "## 1. Tái tạo cấu trúc file của dự án\n",
    "\n",
    "Các cell dưới đây sẽ tạo ra các thư mục và file `.py` cần thiết cho dự án.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5b94f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p ./attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1f4caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ./attacks/quantum_leak.py\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pennylane as qml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from models.qnn_leak import QNN\n",
    "from utils.visualization import plot_model_comparison\n",
    "from utils.training import evaluate_model_with_metrics\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "class HuberLoss(nn.Module):\n",
    "    def __init__(self, delta=1.0):\n",
    "        super(HuberLoss, self).__init__()\n",
    "        self.delta = delta\n",
    "\n",
    "    def forward(self, outputs, targets):\n",
    "        error = outputs - targets\n",
    "        is_small_error = torch.abs(error) <= self.delta\n",
    "        squared_loss = 0.5 * error ** 2\n",
    "        linear_loss = self.delta * torch.abs(error) - 0.5 * self.delta ** 2\n",
    "        loss = torch.where(is_small_error, squared_loss, linear_loss)\n",
    "        return loss.mean()\n",
    "\n",
    "class ModelExtraction(ABC):\n",
    "    def __init__(self, victim_model, n_qubits=4, query_budget=6000, device=\"cuda\", save_path=\"./results\", circuit_device=\"default.mixed\"):\n",
    "        self.victim_model = victim_model\n",
    "        self.n_qubits = n_qubits\n",
    "        self.query_budget = query_budget\n",
    "        self.device = torch.device(device if torch.cuda.is_available() else \"cpu\")\n",
    "        self.save_path = save_path\n",
    "        os.makedirs(save_path, exist_ok=True)\n",
    "        self.circuit_device = circuit_device\n",
    "        self.qnn_zoo = self._create_qnn_zoo()\n",
    "\n",
    "    def _create_quantum_circuit(self, n_layers):\n",
    "        dev = qml.device(self.circuit_device, wires=self.n_qubits)\n",
    "        @qml.qnode(dev, interface=\"torch\", diff_method=\"parameter-shift\")\n",
    "        def circuit(inputs, weights):\n",
    "            qml.AmplitudeEmbedding(inputs, wires=range(self.n_qubits), normalize=True)\n",
    "            for layer in range(n_layers):\n",
    "                for i in range(self.n_qubits):\n",
    "                    qml.RY(weights[layer * self.n_qubits + i], wires=i)\n",
    "                for i in range(self.n_qubits):\n",
    "                    qml.CZ(wires=[i, (i + 1) % self.n_qubits])\n",
    "            return [qml.expval(qml.PauliZ(i)) for i in range(self.n_qubits)]\n",
    "        return circuit\n",
    "\n",
    "    def _create_a1_circuit(self):\n",
    "        dev = qml.device(self.circuit_device, wires=self.n_qubits)\n",
    "        @qml.qnode(dev, interface=\"torch\", diff_method=\"parameter-shift\")\n",
    "        def circuit(inputs, weights):\n",
    "            qml.AmplitudeEmbedding(inputs, wires=range(self.n_qubits), normalize=True)\n",
    "            param_idx = 0\n",
    "            for _ in range(2):\n",
    "                for i in range(self.n_qubits):\n",
    "                    qml.RX(weights[param_idx], wires=i)\n",
    "                    param_idx += 1\n",
    "                    qml.RY(weights[param_idx], wires=i)\n",
    "                    param_idx += 1\n",
    "                    qml.RZ(weights[param_idx], wires=i)\n",
    "                    param_idx += 1\n",
    "                for i in range(self.n_qubits):\n",
    "                    qml.CNOT(wires=[i, (i + 1) % self.n_qubits])\n",
    "            return [qml.expval(qml.PauliZ(i)) for i in range(self.n_qubits)]\n",
    "        return circuit\n",
    "\n",
    "    def _create_a2_circuit(self):\n",
    "        dev = qml.device(self.circuit_device, wires=self.n_qubits)\n",
    "        @qml.qnode(dev, interface=\"torch\", diff_method=\"parameter-shift\")\n",
    "        def circuit(inputs, weights):\n",
    "            qml.AmplitudeEmbedding(inputs, wires=range(self.n_qubits), normalize=True)\n",
    "            param_idx = 0\n",
    "            for _ in range(2):\n",
    "                qml.RX(weights[param_idx], wires=0)\n",
    "                param_idx += 1\n",
    "                qml.RY(weights[param_idx], wires=1)\n",
    "                param_idx += 1\n",
    "                qml.RZ(weights[param_idx], wires=2)\n",
    "                param_idx += 1\n",
    "                qml.RX(weights[param_idx], wires=3)\n",
    "                param_idx += 1\n",
    "                for i in range(self.n_qubits):\n",
    "                    qml.CNOT(wires=[i, (i + 1) % self.n_qubits])\n",
    "            return [qml.expval(qml.PauliZ(i)) for i in range(self.n_qubits)]\n",
    "        return circuit\n",
    "\n",
    "    def _create_qnn_zoo(self):\n",
    "        qnn_zoo = []\n",
    "        for n_layers in [1, 2, 3]:\n",
    "            circuit = self._create_quantum_circuit(n_layers)\n",
    "            model = QNN(self.n_qubits, circuit, n_layers).to(self.device)\n",
    "            model.q_params = nn.Parameter(\n",
    "                torch.tensor(np.random.normal(0, np.pi, (n_layers * self.n_qubits,)),\n",
    "                             dtype=torch.float32, device=self.device, requires_grad=True)\n",
    "            )\n",
    "            qnn_zoo.append((f'L{n_layers}', model))\n",
    "        circuit_a1 = self._create_a1_circuit()\n",
    "        model_a1 = QNN(self.n_qubits, circuit_a1, n_layers=6).to(self.device)\n",
    "        model_a1.q_params = nn.Parameter(\n",
    "            torch.tensor(np.random.normal(0, np.pi, (12 * 2,)),\n",
    "                         dtype=torch.float32, device=self.device, requires_grad=True)\n",
    "        )\n",
    "        qnn_zoo.append(('A1', model_a1))\n",
    "        circuit_a2 = self._create_a2_circuit()\n",
    "        model_a2 = QNN(self.n_qubits, circuit_a2, n_layers=4).to(self.device)\n",
    "        model_a2.q_params = nn.Parameter(\n",
    "            torch.tensor(np.random.normal(0, np.pi, (4 * 2,)),\n",
    "                         dtype=torch.float32, device=self.device, requires_grad=True)\n",
    "        )\n",
    "        qnn_zoo.append(('A2', model_a2))\n",
    "        return qnn_zoo\n",
    "\n",
    "    def qnnaas_predict(self, model, images, device):\n",
    "        model.eval()\n",
    "        images = images.to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(images)\n",
    "            prob_class_1 = outputs\n",
    "            prob_class_0 = 1 - prob_class_1\n",
    "            prob_vectors = torch.cat([prob_class_0, prob_class_1], dim=1)\n",
    "        return prob_vectors\n",
    "\n",
    "    def query_victim(self, data_loader, n_rounds=3):\n",
    "        self.victim_model.eval()\n",
    "        query_dataset = []\n",
    "        samples_per_round = self.query_budget // n_rounds\n",
    "        spam_noise = 0.0054\n",
    "        gate_1q_noise = 0.00177\n",
    "        gate_2q_noise = 0.0287\n",
    "        crosstalk_noise = 0.2\n",
    "        with torch.no_grad():\n",
    "            for round in range(n_rounds):\n",
    "                samples_collected = 0\n",
    "                for inputs, _ in data_loader:\n",
    "                    inputs = inputs.to(self.device)\n",
    "                    outputs = self.qnnaas_predict(self.victim_model, inputs, self.device)\n",
    "                    noise_scale = spam_noise + gate_1q_noise + gate_2q_noise + crosstalk_noise\n",
    "                    noise = torch.randn_like(outputs) * noise_scale\n",
    "                    noisy_outputs = outputs + noise\n",
    "                    noisy_outputs = torch.clamp(noisy_outputs, 0, 1)\n",
    "                    query_dataset.append((inputs.cpu().numpy(), noisy_outputs.cpu().numpy()))\n",
    "                    samples_collected += inputs.size(0)\n",
    "                    if samples_collected >= samples_per_round:\n",
    "                        break\n",
    "                print(f\"Completed query round {round + 1}/{n_rounds}\")\n",
    "        return query_dataset\n",
    "\n",
    "    def generate_adversarial_samples(self, model, inputs, targets, epsilon=0.01):\n",
    "        model.eval()\n",
    "        inputs = inputs.clone().detach().to(self.device)\n",
    "        with torch.no_grad():\n",
    "            outputs = self.qnnaas_predict(model, inputs, self.device)\n",
    "            probs = outputs[:, 1]\n",
    "            boundary_mask = (probs >= 0.4) & (probs <= 0.6)\n",
    "            if not boundary_mask.any():\n",
    "                return inputs\n",
    "            boundary_inputs = inputs[boundary_mask]\n",
    "            noise = epsilon * torch.randn_like(boundary_inputs)\n",
    "            adv_inputs = boundary_inputs + noise\n",
    "            adv_inputs = torch.clamp(adv_inputs, 0, 1)\n",
    "            inputs[boundary_mask] = adv_inputs\n",
    "        return inputs\n",
    "\n",
    "    @abstractmethod\n",
    "    def train(self, *args, **kwargs):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def evaluate(self, *args, **kwargs):\n",
    "        pass\n",
    "\n",
    "class CloudLeak(ModelExtraction):\n",
    "    def pretrain(self, public_loader, n_epochs=10, batch_size=8, architecture='L2', save=True):\n",
    "        criterion = nn.BCEWithLogitsLoss()\n",
    "        architecture_map = {name: model for name, model in self.qnn_zoo}\n",
    "        model = architecture_map[architecture]\n",
    "        model.q_params = nn.Parameter(\n",
    "            torch.normal(mean=0, std=np.pi, size=(model.n_layers * self.n_qubits,), device=self.device)\n",
    "        )\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "        history = {'pretrain_loss': [], 'pretrain_accuracy': []}\n",
    "        for epoch in tqdm(range(n_epochs), desc=\"Pretraining CloudLeak\"):\n",
    "            model.train()\n",
    "            running_loss = 0.0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for inputs, targets in public_loader:\n",
    "                inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "                targets = targets.view(-1, 1).float()\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "                predicted = (torch.sigmoid(outputs) >= 0.5).float().squeeze()\n",
    "                total += targets.size(0)\n",
    "                correct += (predicted == targets.squeeze()).sum().item()\n",
    "            avg_loss = running_loss / len(public_loader)\n",
    "            accuracy = 100 * correct / total\n",
    "            history['pretrain_loss'].append(avg_loss)\n",
    "            history['pretrain_accuracy'].append(accuracy)\n",
    "            print(f\"Pretrain Epoch {epoch+1}, Loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n",
    "        if save:\n",
    "            save_path = os.path.join(self.save_path, f'pretrained_cloudleak_{architecture}.pth')\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            print(f\"Pretrained model saved to {save_path}\")\n",
    "        return model, history\n",
    "\n",
    "    def load_pretrained_model(self, architecture='L2'):\n",
    "        architecture_map = {name: model for name, model in self.qnn_zoo}\n",
    "        if architecture not in architecture_map:\n",
    "            raise ValueError(f\"Architecture {architecture} not found in QNN zoo.\")\n",
    "        model = architecture_map[architecture]\n",
    "        pretrained_path = os.path.join(self.save_path, f'pretrained_cloudleak_{architecture}.pth')\n",
    "        if os.path.exists(pretrained_path):\n",
    "            model.load_state_dict(torch.load(pretrained_path, map_location=self.device))\n",
    "            print(f\"Loaded pretrained model from {pretrained_path}\")\n",
    "            return model\n",
    "        else:\n",
    "            print(f\"No pretrained model found at {pretrained_path}\")\n",
    "            return None\n",
    "\n",
    "    def train(self, query_dataset, out_of_domain_loader, n_epochs=20, batch_size=8, architecture='L2', loss_type='nll'):\n",
    "        criterion = HuberLoss(delta=0.5) if loss_type == 'huber' else nn.BCEWithLogitsLoss()\n",
    "        architecture_map = {name: model for name, model in self.qnn_zoo}\n",
    "        model = self.load_pretrained_model(architecture)\n",
    "        if model is None:\n",
    "            public_inputs, public_targets = [], []\n",
    "            for inputs, targets in out_of_domain_loader:\n",
    "                public_inputs.append(inputs.cpu().numpy())\n",
    "                public_targets.append(targets.cpu().numpy())\n",
    "            public_inputs = np.concatenate(public_inputs)[:3000]\n",
    "            public_targets = np.concatenate(public_targets)[:3000]\n",
    "            public_dataset = TensorDataset(\n",
    "                torch.tensor(public_inputs, dtype=torch.float32),\n",
    "                torch.tensor(public_targets, dtype=torch.float32).view(-1, 1)\n",
    "            )\n",
    "            public_loader = DataLoader(public_dataset, batch_size=batch_size, shuffle=True)\n",
    "            model, pretrain_history = self.pretrain(public_loader, n_epochs=10, batch_size=batch_size, architecture=architecture)\n",
    "        else:\n",
    "            pretrain_history = {'pretrain_loss': [], 'pretrain_accuracy': []}\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "        history = {'train_loss': [], 'train_accuracy': []}\n",
    "        out_inputs, out_targets = [], []\n",
    "        for inputs, targets in out_of_domain_loader:\n",
    "            out_inputs.append(inputs.cpu().numpy())\n",
    "            out_targets.append(targets.cpu().numpy())\n",
    "            if len(np.concatenate(out_inputs)) >= 500:\n",
    "                break\n",
    "        out_inputs = np.concatenate(out_inputs)[:500]\n",
    "        out_targets = np.concatenate(out_targets)[:500]\n",
    "        query_inputs = np.concatenate([item[0] for item in query_dataset])\n",
    "        query_outputs = np.concatenate([item[1][:, 1:2] for item in query_dataset])\n",
    "        query_inputs_tensor = torch.tensor(query_inputs, dtype=torch.float32, device=self.device)\n",
    "        query_targets_tensor = torch.tensor(query_outputs, dtype=torch.float32, device=self.device)\n",
    "        adv_inputs = self.generate_adversarial_samples(self.victim_model, query_inputs_tensor, query_targets_tensor)\n",
    "        adv_inputs = adv_inputs.cpu().numpy()\n",
    "        adv_outputs = query_outputs\n",
    "        synthetic_inputs = np.concatenate([out_inputs, query_inputs, adv_inputs])\n",
    "        synthetic_outputs = np.concatenate([out_targets[:, None], query_outputs, adv_outputs])\n",
    "        synthetic_dataset = TensorDataset(\n",
    "            torch.tensor(synthetic_inputs, dtype=torch.float32),\n",
    "            torch.tensor(synthetic_outputs, dtype=torch.float32).view(-1, 1)\n",
    "        )\n",
    "        synthetic_loader = DataLoader(synthetic_dataset, batch_size=batch_size, shuffle=True)\n",
    "        for epoch in tqdm(range(n_epochs), desc=\"Training CloudLeak\"):\n",
    "            model.train()\n",
    "            running_loss = 0.0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for inputs, targets in synthetic_loader:\n",
    "                inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "                targets = targets.view(-1, 1).float()\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "                predicted = (torch.sigmoid(outputs) >= 0.5).float().squeeze()\n",
    "                total += targets.size(0)\n",
    "                correct += (predicted == targets.squeeze()).sum().item()\n",
    "            avg_loss = running_loss / len(synthetic_loader)\n",
    "            accuracy = 100 * correct / total\n",
    "            history['train_loss'].append(avg_loss)\n",
    "            history['train_accuracy'].append(accuracy)\n",
    "            print(f\"Epoch {epoch+1}, Loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n",
    "        return model, {**pretrain_history, **history}\n",
    "\n",
    "    def evaluate(self, model, test_loader):\n",
    "        metrics = evaluate_model_with_metrics(model, test_loader, self.device)\n",
    "        return metrics\n",
    "\n",
    "class QuantumLeak(ModelExtraction):\n",
    "    def __init__(self, victim_model, n_qubits=4, query_budget=6000, n_committee=3, device=\"cuda\", save_path=\"./results\", circuit_device=\"default.mixed\"):\n",
    "        super().__init__(victim_model, n_qubits, query_budget, device, save_path, circuit_device)\n",
    "        self.n_committee = n_committee\n",
    "        self.ensemble_models = []\n",
    "\n",
    "    def train(self, query_dataset, out_of_domain_loader, n_epochs=30, batch_size=8, architecture='L2', loss_type='huber'):\n",
    "        return self.train_ensemble(query_dataset, n_epochs, batch_size, architecture, loss_type, self.n_committee)\n",
    "\n",
    "    def train_ensemble(self, query_dataset, n_epochs=30, batch_size=8, architecture='L2', loss_type='huber', n_committee=None):\n",
    "        n_committee = n_committee or self.n_committee\n",
    "        criterion = HuberLoss(delta=0.5) if loss_type == 'huber' else nn.BCEWithLogitsLoss()\n",
    "        dataset_size = len(query_dataset)\n",
    "        subset_size = dataset_size // n_committee\n",
    "        ensemble_models = []\n",
    "        history = {'train_loss': [], 'train_accuracy': []}\n",
    "        architecture_map = {name: model for name, model in self.qnn_zoo}\n",
    "        if architecture not in architecture_map:\n",
    "            raise ValueError(f\"Architecture {architecture} not found in QNN zoo.\")\n",
    "        base_model = architecture_map[architecture]\n",
    "        base_circuit = base_model.quantum_circuit\n",
    "        vqc_layers = base_model.n_layers\n",
    "        for i in range(n_committee):\n",
    "            model = QNN(self.n_qubits, base_circuit, vqc_layers).to(self.device)\n",
    "            param_size = 12 * 2 if architecture == 'A1' else (4 * 2 if architecture == 'A2' else vqc_layers * self.n_qubits)\n",
    "            model.q_params = nn.Parameter(\n",
    "                torch.normal(mean=0, std=np.pi, size=(param_size,)).to(self.device)\n",
    "            )\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "            subset_indices = np.random.choice(dataset_size, subset_size, replace=True)\n",
    "            subset_data = [query_dataset[idx] for idx in subset_indices]\n",
    "            inputs = np.concatenate([item[0] for item in subset_data])\n",
    "            outputs = np.concatenate([item[1][:, 1:2] for item in subset_data])\n",
    "            subset_dataset = TensorDataset(\n",
    "                torch.tensor(inputs, dtype=torch.float32),\n",
    "                torch.tensor(outputs, dtype=torch.float32).view(-1, 1)\n",
    "            )\n",
    "            subset_loader = DataLoader(subset_dataset, batch_size=batch_size, shuffle=True)\n",
    "            for epoch in range(n_epochs):\n",
    "                model.train()\n",
    "                running_loss = 0.0\n",
    "                correct = 0\n",
    "                total = 0\n",
    "                for inputs, targets in subset_loader:\n",
    "                    inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "                    targets = targets.view(-1, 1).float()\n",
    "                    optimizer.zero_grad()\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, targets)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    running_loss += loss.item()\n",
    "                    predicted = (torch.sigmoid(outputs) >= 0.5).float().squeeze()\n",
    "                    target_labels = (targets >= 0.5).float().squeeze()\n",
    "                    total += targets.size(0)\n",
    "                    correct += (predicted == target_labels).sum().item()\n",
    "                avg_loss = running_loss / len(subset_loader)\n",
    "                accuracy = 100 * correct / total\n",
    "                history['train_loss'].append(avg_loss)\n",
    "                history['train_accuracy'].append(accuracy)\n",
    "                print(f\"Committee {i+1}, Epoch {epoch+1}, Loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n",
    "            ensemble_models.append(model)\n",
    "        self.ensemble_models = ensemble_models\n",
    "        return ensemble_models, history\n",
    "\n",
    "    def evaluate(self, test_loader):\n",
    "        metrics = evaluate_model_with_metrics(self.ensemble_models, test_loader, self.device, is_ensemble=True)\n",
    "        return metrics\n",
    "\n",
    "    def ablation_study(self, data_loader, test_loader, out_of_domain_loader, query_budgets=[1500, 3000, 6000], architectures=['L1', 'L2', 'L3', 'A1', 'A2'], committee_numbers=[3, 5, 7], epochs=30):\n",
    "        results = []\n",
    "        cloud_leak = CloudLeak(\n",
    "            self.victim_model, self.n_qubits, self.query_budget, self.device, self.save_path, self.circuit_device\n",
    "        )\n",
    "        public_inputs, public_targets = [], []\n",
    "        for inputs, targets in out_of_domain_loader:\n",
    "            public_inputs.append(inputs.cpu().numpy())\n",
    "            public_targets.append(targets.cpu().numpy())\n",
    "        public_inputs = np.concatenate(public_inputs)[:3000]\n",
    "        public_targets = np.concatenate(public_targets)[:3000]\n",
    "        public_dataset = TensorDataset(\n",
    "            torch.tensor(public_inputs, dtype=torch.float32),\n",
    "            torch.tensor(public_targets, dtype=torch.float32)\n",
    "        )\n",
    "        public_loader = DataLoader(public_dataset, batch_size=8, shuffle=True)\n",
    "        cloud_leak.pretrain(public_loader, n_epochs=10, batch_size=8, architecture='L2')\n",
    "        for query_budget in query_budgets:\n",
    "            self.query_budget = query_budget\n",
    "            query_dataset = self.query_victim(data_loader, n_rounds=3)\n",
    "            for architecture in architectures:\n",
    "                for n_committee in committee_numbers:\n",
    "                    for scheme in ['Single-N', 'Single-H', 'Ens-N', 'Ens-H']:\n",
    "                        if 'Single' in scheme:\n",
    "                            loss_type = 'nll' if scheme == 'Single-N' else 'huber'\n",
    "                            model, _ = cloud_leak.train(\n",
    "                                query_dataset, out_of_domain_loader, n_epochs=20,\n",
    "                                batch_size=8, architecture=architecture, loss_type=loss_type\n",
    "                            )\n",
    "                            metrics = cloud_leak.evaluate(model, test_loader)\n",
    "                        else:\n",
    "                            loss_type = 'nll' if scheme == 'Ens-N' else 'huber'\n",
    "                            ensemble_models, _ = self.train_ensemble(\n",
    "                                query_dataset, n_epochs=epochs, batch_size=8, architecture=architecture,\n",
    "                                loss_type=loss_type, n_committee=n_committee\n",
    "                            )\n",
    "                            metrics = self.evaluate(test_loader)\n",
    "                        results.append({\n",
    "                            'Query Budget': query_budget,\n",
    "                            'Architecture': architecture,\n",
    "                            'Committee': n_committee,\n",
    "                            'Scheme': scheme,\n",
    "                            'Accuracy': metrics['accuracy'],\n",
    "                            'Precision': metrics['precision'],\n",
    "                            'Recall': metrics['recall'],\n",
    "                            'F1': metrics['f1']\n",
    "                        })\n",
    "                        print(f\"Query Budget: {query_budget}, Architecture: {architecture}, Committee: {n_committee}, \"\n",
    "                              f\"Scheme: {scheme}, Accuracy: {metrics['accuracy']:.2f}%, \"\n",
    "                              f\"Precision: {metrics['precision']:.2f}, Recall: {metrics['recall']:.2f}, F1: {metrics['f1']:.2f}\")\n",
    "        results_df = pd.DataFrame(results)\n",
    "        results_df.to_csv(os.path.join(self.save_path, 'ablation_results.csv'), index=False)\n",
    "        return results\n",
    "\n",
    "    def plot_ablation_results(self, results_df):\n",
    "        import matplotlib.pyplot as plt\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        df_fig4 = results_df[(results_df['Query Budget'] == 6000) & (results_df['Architecture'] == 'L2') & (results_df['Committee'] == 5)]\n",
    "        schemes = df_fig4['Scheme'].values\n",
    "        accuracies = df_fig4['Accuracy'].values\n",
    "        plt.bar(schemes, accuracies, color=['blue', 'green', 'orange', 'red'])\n",
    "        plt.xlabel('Attack Scheme')\n",
    "        plt.ylabel('Accuracy (%)')\n",
    "        plt.title('Figure 4: Comparison of Attack Schemes')\n",
    "        plt.savefig(os.path.join(self.save_path, 'figure4.png'))\n",
    "        plt.close()\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        df_fig5 = results_df[(results_df['Query Budget'] == 6000) & (results_df['Scheme'] == 'Ens-H') & (results_df['Committee'] == 5)]\n",
    "        architectures = df_fig5['Architecture'].values\n",
    "        accuracies = df_fig5['Accuracy'].values\n",
    "        plt.bar(architectures, accuracies, color='purple')\n",
    "        plt.xlabel('VQC Architecture')\n",
    "        plt.ylabel('Accuracy (%)')\n",
    "        plt.title('Figure 5: Impact of VQC Ansatz')\n",
    "        plt.savefig(os.path.join(self.save_path, 'figure5.png'))\n",
    "        plt.close()\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        df_fig6 = results_df[(results_df['Query Budget'] == 6000) & (results_df['Architecture'] == 'L2') & (results_df['Scheme'] == 'Ens-H')]\n",
    "        committees = df_fig6['Committee'].values\n",
    "        accuracies = df_fig6['Accuracy'].values\n",
    "        plt.plot(committees, accuracies, marker='o', label='Ens-H')\n",
    "        plt.xlabel('Number of Committee Members')\n",
    "        plt.ylabel('Accuracy (%)')\n",
    "        plt.title('Figure 6: Impact of Committee Number')\n",
    "        plt.legend()\n",
    "        plt.savefig(os.path.join(self.save_path, 'figure6.png'))\n",
    "        plt.close()\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        for arch in ['L1', 'L2', 'L3']:\n",
    "            df_fig7 = results_df[(results_df['Architecture'] == arch) & (results_df['Scheme'] == 'Ens-H') & (results_df['Committee'] == 5)]\n",
    "            query_budgets = df_fig7['Query Budget'].values\n",
    "            accuracies = df_fig7['Accuracy'].values\n",
    "            plt.plot(query_budgets, accuracies, marker='o', label=f'{arch}')\n",
    "        plt.xlabel('Query Budget')\n",
    "        plt.ylabel('Accuracy (%)')\n",
    "        plt.title('Figure 7: Performance with Different VQC Layers')\n",
    "        plt.legend()\n",
    "        plt.savefig(os.path.join(self.save_path, 'figure7.png'))\n",
    "        plt.close()\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        for arch in ['L1', 'L2', 'L3']:\n",
    "            df_fig8 = results_df[(results_df['Architecture'] == arch) & (results_df['Scheme'] == 'Ens-H') & (results_df['Committee'] == 5)]\n",
    "            query_budgets = df_fig8['Query Budget'].values\n",
    "            accuracies = df_fig8['Accuracy'].values\n",
    "            plt.plot(query_budgets, accuracies, marker='o', label=f'{arch}')\n",
    "        plt.xlabel('Query Budget')\n",
    "        plt.ylabel('Accuracy (%)')\n",
    "        plt.title('Figure 8: Performance with Query Budgets')\n",
    "        plt.legend()\n",
    "        plt.savefig(os.path.join(self.save_path, 'figure8.png'))\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3303e7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p ./configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0bd485",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ./configs/config.py\n",
    "\n",
    " \n",
    "import os\n",
    "import torch\n",
    "\n",
    "# Paths\n",
    "SAVE_PATH = \"./saved_models\"\n",
    "QUANTUM_LEAK_SAVE_PATH = \"./results\"\n",
    "DATA_PATH = \"./data\"\n",
    "\n",
    "# Hyperparameters\n",
    "N_EPOCHS = 30\n",
    "N_LAYERS = 2\n",
    "N_TRAIN = 5000\n",
    "N_TEST = 1000\n",
    "N_QUBITS = 4\n",
    "BATCH_SIZE = 8\n",
    "LEARNING_RATE = 0.001\n",
    "PREPROCESS = True\n",
    "N_LEAK_EPOCHS = 30\n",
    "N_LEAK_LAYERS = 4\n",
    "N_LEAK_TRAIN = 50000\n",
    "N_LEAK_TEST = 10000\n",
    "N_LEAK_QUBITS = 4\n",
    "LEAK_BATCH_SIZE = 8\n",
    "LEAK_QUERY_BUDGET = 6000\n",
    "LEAK_N_COMMITTEE = 3\n",
    "\n",
    "# Device\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "QUANTUM_DEVICE = \"lightning.qubit\" if torch.cuda.is_available() else \"default.qubit\"\n",
    "\n",
    "# Ensure directories exist\n",
    "os.makedirs(SAVE_PATH, exist_ok=True)\n",
    "os.makedirs(QUANTUM_LEAK_SAVE_PATH, exist_ok=True)\n",
    "os.makedirs(DATA_PATH, exist_ok=True)\n",
    "os.makedirs(SAVE_PATH + \"/quanv\", exist_ok=True)\n",
    "os.makedirs(SAVE_PATH + \"/basic_qnn\", exist_ok=True)\n",
    "os.makedirs(SAVE_PATH + \"/circuit14\", exist_ok=True)\n",
    "os.makedirs(SAVE_PATH + \"/transfer_learning\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a1dd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p ./models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffdcdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ./models/basic_qnn.py\n",
    "\n",
    " \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class BasicQNN(nn.Module):\n",
    "    def __init__(self, n_qubits, quantum_circuit):\n",
    "        super(BasicQNN, self).__init__()\n",
    "        self.conv = nn.Conv2d(1, 16, kernel_size=3, stride=2)\n",
    "        self.pre_net = nn.Linear(16 * 15 * 15, n_qubits)\n",
    "        self.q_params = nn.Parameter(torch.randn(n_qubits))\n",
    "        self.post_net = nn.Linear(n_qubits, 1)\n",
    "        self.quantum_circuit = quantum_circuit\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv(x))\n",
    "        x = x.view(-1, 16 * 15 * 15)\n",
    "        x = torch.tanh(self.pre_net(x))\n",
    "        batch_size = x.size(0)\n",
    "        x_device = x.device\n",
    "        x = [self.quantum_circuit(x[i], self.q_params) for i in range(batch_size)]\n",
    "        x = torch.tensor(x, dtype=torch.float32, device=x_device)\n",
    "        x = torch.sigmoid(self.post_net(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085e438f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ./models/circuit14.py\n",
    "\n",
    " \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pennylane as qml\n",
    "\n",
    "class QuantumLayer(nn.Module):\n",
    "    def __init__(self, n_qubits, n_layers, quantum_circuit, device_name=\"lightning.qubit\"):\n",
    "        super(QuantumLayer, self).__init__()\n",
    "        self.n_qubits = n_qubits\n",
    "        self.n_layers = n_layers\n",
    "        self.conv = nn.Conv2d(1, 16, kernel_size=3, stride=2)\n",
    "        self.pre_net = nn.Linear(16 * 15 * 15, 16)\n",
    "        self.weights = nn.Parameter(torch.randn(n_layers, n_qubits, 3))\n",
    "        self.crx_weights = nn.Parameter(torch.randn(n_layers, 6))\n",
    "        self.fc = nn.Linear(n_qubits, 1)\n",
    "        self.dev = qml.device(device_name, wires=n_qubits, shots=None)\n",
    "        self.quantum_circuit = quantum_circuit\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = torch.relu(self.conv(inputs))\n",
    "        x = x.view(-1, 16 * 15 * 15)\n",
    "        x = torch.tanh(self.pre_net(x))\n",
    "        x = torch.nn.functional.normalize(x, p=2, dim=1, eps=1e-8)\n",
    "\n",
    "        batch_size = x.size(0)\n",
    "        outputs = []\n",
    "        for i in range(batch_size):\n",
    "            q_out = self.quantum_circuit(x[i], self.weights, self.crx_weights)\n",
    "            q_out = torch.stack(q_out).float()\n",
    "            outputs.append(q_out)\n",
    "        outputs = torch.stack(outputs)\n",
    "        probs = self.fc(outputs).sigmoid()\n",
    "        return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41094ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ./models/qnn_leak.py\n",
    "\n",
    " \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pennylane as qml\n",
    "import numpy as np\n",
    "\n",
    "class QNN(nn.Module):\n",
    "    def __init__(self, n_qubits, quantum_circuit, n_layers):\n",
    "        super(QNN, self).__init__()\n",
    "        self.pool = nn.AvgPool2d(kernel_size=8, stride=8)\n",
    "        self.pre_net = nn.Linear(16, 16)\n",
    "        self.q_params = nn.Parameter(torch.normal(mean=0, std=np.pi, size=(n_layers * n_qubits,)))\n",
    "        self.post_net = nn.Linear(n_qubits, 1)\n",
    "        self.quantum_circuit = quantum_circuit\n",
    "        self.n_qubits = n_qubits\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(x)\n",
    "        x = x.view(-1, 16)\n",
    "        x = torch.tanh(self.pre_net(x))\n",
    "        batch_size = x.size(0)\n",
    "        x_device = x.device\n",
    "        x = torch.nn.functional.normalize(x, p=2, dim=1)\n",
    "        x = [self.quantum_circuit(x[i], self.q_params) for i in range(batch_size)]\n",
    "        x = torch.tensor(x, dtype=torch.float32, device=x_device)\n",
    "        x = torch.sigmoid(self.post_net(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb04417",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ./models/quanv_model.py\n",
    "\n",
    " \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class QuanvModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(QuanvModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(4, 32, kernel_size=3, stride=1, padding=0)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=0)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(64 * 2 * 2, 64)\n",
    "        self.fc2 = nn.Linear(64, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.sigmoid(self.fc2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339825f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ./models/transfer_learning.py\n",
    "\n",
    " \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pennylane as qml\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "\n",
    "class DressedQuantumCircuit(nn.Module):\n",
    "    def __init__(self, n_qubits, n_layers, device_name=\"default.qubit\"):\n",
    "        super(DressedQuantumCircuit, self).__init__()\n",
    "        self.n_qubits = n_qubits\n",
    "        self.n_layers = n_layers\n",
    "        self.pre_net = nn.Linear(512, n_qubits)\n",
    "        self.post_net = nn.Linear(n_qubits, 1)\n",
    "        self.weights = nn.Parameter(torch.randn(n_layers, n_qubits, requires_grad=True))\n",
    "        self.dev = qml.device(device_name, wires=n_qubits)\n",
    "        self.quantum_circuit = self._create_quantum_circuit()\n",
    "\n",
    "    def _create_quantum_circuit(self):\n",
    "        @qml.qnode(self.dev, interface=\"torch\", diff_method=\"parameter-shift\")\n",
    "        def quantum_circuit(inputs, weights):\n",
    "            for i in range(self.n_qubits):\n",
    "                qml.Hadamard(wires=i)\n",
    "                qml.RY(inputs[i] * np.pi / 2, wires=i)\n",
    "            for layer in range(self.n_layers):\n",
    "                for i in range(self.n_qubits):\n",
    "                    qml.RY(weights[layer, i], wires=i)\n",
    "                for i in range(self.n_qubits - 1):\n",
    "                    qml.CNOT(wires=[i, i + 1])\n",
    "            return [qml.expval(qml.PauliZ(i)) for i in range(self.n_qubits)]\n",
    "        return quantum_circuit\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pre_net(x)\n",
    "        q_out = torch.zeros(x.size(0), self.n_qubits, dtype=torch.float32).to(x.device)\n",
    "        for i in range(x.size(0)):\n",
    "            q_out[i] = torch.tensor(self.quantum_circuit(x[i], self.weights), dtype=torch.float32).to(x.device)\n",
    "        return torch.sigmoid(self.post_net(q_out))\n",
    "\n",
    "class CQTransferLearningModel(nn.Module):\n",
    "    def __init__(self, n_qubits, n_layers):\n",
    "        super(CQTransferLearningModel, self).__init__()\n",
    "        self.resnet = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
    "        self.resnet.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        nn.init.kaiming_normal_(self.resnet.conv1.weight, mode='fan_out', nonlinearity='relu')\n",
    "        self.resnet.fc = nn.Identity()\n",
    "        for param in self.resnet.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.quantum_net = DressedQuantumCircuit(n_qubits, n_layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.resnet(x)\n",
    "        return self.quantum_net(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9b47f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p ./quantum_circuits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6b2941",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ./quantum_circuits/basic_qnn_circuit.py\n",
    "\n",
    " \n",
    "import pennylane as qml\n",
    "import torch\n",
    "from configs.config import N_QUBITS, N_LAYERS, QUANTUM_DEVICE\n",
    "\n",
    "def create_quantum_circuit(n_qubits=N_QUBITS, n_layers=N_LAYERS, device_name=QUANTUM_DEVICE):\n",
    "    dev = qml.device(device_name, wires=n_qubits)\n",
    "    @qml.qnode(dev, interface=\"torch\", diff_method=\"parameter-shift\")\n",
    "    def circuit(inputs, weights):\n",
    "        for layer in range(n_layers):\n",
    "            for i in range(n_qubits):\n",
    "                qml.RX(inputs[..., i], wires=i)\n",
    "                qml.RY(weights[i], wires=i)\n",
    "            for i in range(n_qubits - 1):\n",
    "                qml.CZ(wires=[i, i + 1])\n",
    "        return [qml.expval(qml.PauliZ(i)) for i in range(n_qubits)]\n",
    "    return circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a701bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ./quantum_circuits/circuit14_circuit.py\n",
    "\n",
    " \n",
    "import pennylane as qml\n",
    "import torch\n",
    "from configs.config import N_QUBITS, N_LAYERS, QUANTUM_DEVICE\n",
    "\n",
    "def create_circuit14(n_qubits=N_QUBITS, n_layers=N_LAYERS, device_name=QUANTUM_DEVICE):\n",
    "    dev = qml.device(device_name, wires=n_qubits, shots=None)\n",
    "    @qml.qnode(dev, interface='torch', diff_method='parameter-shift')\n",
    "    def circuit_14(inputs, weights, crx_weights):\n",
    "        qml.AmplitudeEmbedding(inputs, wires=range(n_qubits), normalize=True, pad_with=0.)\n",
    "        for l in range(n_layers):\n",
    "            for qubit in range(n_qubits):\n",
    "                qml.RX(weights[l, qubit, 0], wires=qubit)\n",
    "                qml.RY(weights[l, qubit, 1], wires=qubit)\n",
    "                qml.RZ(weights[l, qubit, 2], wires=qubit)\n",
    "            crx_idx = 0\n",
    "            for qubit in range(n_qubits - 1):\n",
    "                qml.CRX(crx_weights[l, crx_idx], wires=[qubit, qubit + 1])\n",
    "                crx_idx += 1\n",
    "            qml.CRX(crx_weights[l, crx_idx], wires=[n_qubits - 1, 0])\n",
    "            crx_idx += 1\n",
    "            for qubit in [0, 1]:\n",
    "                target = (qubit + 3) % n_qubits\n",
    "                qml.CRX(crx_weights[l, crx_idx], wires=[qubit, target])\n",
    "                crx_idx += 1\n",
    "        return [qml.expval(qml.PauliZ(j)) for j in range(n_qubits)]\n",
    "    return circuit_14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a676887e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ./quantum_circuits/quanv_circuit.py\n",
    "\n",
    " \n",
    "import pennylane as qml\n",
    "import numpy as np\n",
    "from configs.config import N_LAYERS, N_QUBITS, QUANTUM_DEVICE\n",
    "\n",
    "def create_quanv_circuit():\n",
    "    try:\n",
    "        dev = qml.device(QUANTUM_DEVICE, wires=4)\n",
    "    except:\n",
    "        dev = qml.device(\"default.qubit\", wires=4)\n",
    "    rand_params = np.random.uniform(high=2 * np.pi, size=(N_LAYERS, 4))\n",
    "\n",
    "    @qml.qnode(dev)\n",
    "    def circuit(phi):\n",
    "        for j in range(4):\n",
    "            qml.RY(np.pi * phi[j], wires=j)\n",
    "        qml.templates.RandomLayers(rand_params, wires=list(range(4)))\n",
    "        return [qml.expval(qml.PauliZ(j)) for j in range(4)]\n",
    "    return circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04150b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ./quantum_circuits/transfer_learning_circuit.py\n",
    "\n",
    " \n",
    "import pennylane as qml\n",
    "import torch\n",
    "from configs.config import N_QUBITS, N_LAYERS, QUANTUM_DEVICE\n",
    "\n",
    "def create_transfer_learning_circuit(n_qubits=N_QUBITS, n_layers=N_LAYERS, device_name=QUANTUM_DEVICE):\n",
    "    dev = qml.device(device_name, wires=n_qubits)\n",
    "    @qml.qnode(dev, interface=\"torch\", diff_method=\"parameter-shift\")\n",
    "    def quantum_circuit(inputs, weights):\n",
    "        for i in range(n_qubits):\n",
    "            qml.Hadamard(wires=i)\n",
    "            qml.RY(inputs[i] * np.pi / 2, wires=i)\n",
    "        for layer in range(n_layers):\n",
    "            for i in range(n_qubits):\n",
    "                qml.RY(weights[layer, i], wires=i)\n",
    "            for i in range(n_qubits - 1):\n",
    "                qml.CNOT(wires=[i, i + 1])\n",
    "        return [qml.expval(qml.PauliZ(i)) for i in range(n_qubits)]\n",
    "    return quantum_circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d080c79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p ./utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342417e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ./utils/training.py\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "def train_model(model, train_loader, val_loader, device, criterion, n_epochs, learning_rate, save_path):\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    train_losses = []\n",
    "    val_accuracies = []\n",
    "    best_val_accuracy = 0.0\n",
    "    best_model_path = f\"{save_path}/best_model.pth\"\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels.view(-1, 1).float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        avg_train_loss = running_loss / len(train_loader)\n",
    "        train_losses.append(avg_train_loss)\n",
    "        val_metrics = evaluate_model_with_metrics(model, val_loader, device, criterion)\n",
    "        val_accuracies.append(val_metrics['accuracy'])\n",
    "        print(f\"Epoch {epoch+1}/{n_epochs}, Train Loss: {avg_train_loss:.4f}, \"\n",
    "              f\"Val Accuracy: {val_metrics['accuracy']:.2f}%, \"\n",
    "              f\"Precision: {val_metrics['precision']:.2f}, \"\n",
    "              f\"Recall: {val_metrics['recall']:.2f}, \"\n",
    "              f\"F1: {val_metrics['f1']:.2f}\")\n",
    "        if val_metrics['accuracy'] > best_val_accuracy:\n",
    "            best_val_accuracy = val_metrics['accuracy']\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "    return train_losses, val_accuracies\n",
    "\n",
    "def evaluate_model_with_metrics(models, data_loader, device, criterion=None, is_ensemble=False):\n",
    "    if not isinstance(models, (list, tuple)):\n",
    "        models = [models]\n",
    "    for model in models:\n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    total_loss = 0.0 if criterion is not None else None\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in data_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            labels = labels.float().squeeze()\n",
    "            if is_ensemble:\n",
    "                ensemble_outputs = []\n",
    "                for model in models:\n",
    "                    outputs = model(inputs)\n",
    "                    ensemble_outputs.append(outputs)\n",
    "                outputs = torch.stack(ensemble_outputs).mean(dim=0)\n",
    "            else:\n",
    "                outputs = models[0](inputs)\n",
    "            probs = torch.sigmoid(outputs).squeeze()\n",
    "            predicted = (probs >= 0.5).float()\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            if criterion is not None:\n",
    "                loss = criterion(outputs, labels.view(-1, 1)).item()\n",
    "                total_loss += loss * len(labels)\n",
    "    accuracy = 100 * np.mean(np.array(all_preds) == np.array(all_labels))\n",
    "    precision = precision_score(all_labels, all_preds, average='binary', zero_division=0)\n",
    "    recall = recall_score(all_labels, all_preds, average='binary', zero_division=0)\n",
    "    f1 = f1_score(all_labels, all_preds, average='binary', zero_division=0)\n",
    "    metrics = {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }\n",
    "    if criterion is not None:\n",
    "        metrics['loss'] = total_loss / len(all_labels)\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05b2560",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ./utils/visualization.py\n",
    "\n",
    " \n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def plot_training_history(history, save_path, title=\"Training History\"):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    if 'train_loss' in history:\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(history['train_loss'], label='Training Loss')\n",
    "        plt.title('Model Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "    if 'test_accuracy' in history:\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(history['test_accuracy'], label='Test Accuracy')\n",
    "        plt.title('Model Accuracy')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Accuracy (%)')\n",
    "        plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(save_path, f'{title.lower().replace(\" \", \"_\")}.png'))\n",
    "    plt.close()\n",
    "\n",
    "def plot_quanv_visualization(train_images, q_train_images, save_path, n_samples=4, n_channels=4):\n",
    "    q_train_images_np = q_train_images.cpu().numpy().transpose(0, 2, 3, 1)\n",
    "    fig, axes = plt.subplots(1 + n_channels, n_samples, figsize=(10, 10))\n",
    "    for k in range(n_samples):\n",
    "        axes[0, 0].set_ylabel(\"Input\")\n",
    "        if k != 0:\n",
    "            axes[0, k].yaxis.set_visible(False)\n",
    "        axes[0, k].imshow(train_images[k, :, :, 0], cmap=\"gray\")\n",
    "        for c in range(n_channels):\n",
    "            axes[c + 1, 0].set_ylabel(f\"Output [ch. {c}]\")\n",
    "            if k != 0:\n",
    "                axes[c + 1, k].yaxis.set_visible(False)\n",
    "            axes[c + 1, k].imshow(q_train_images_np[k, :, :, c], cmap=\"gray\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(save_path, 'quanv_visualization.png'))\n",
    "    plt.close()\n",
    "\n",
    "def plot_model_comparison(accuracies, labels, save_path, title=\"Model Comparison\"):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(labels, accuracies, color=['blue', 'orange', 'green'])\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.title(title)\n",
    "    plt.savefig(os.path.join(save_path, 'model_comparison.png'))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02e6c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile main.py\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from configs.config import *\n",
    "from data.data_pipeline import CIFAR10DataPipeline, get_cq_dataloaders, create_out_of_domain_loader\n",
    "from models.quanv_model import QuanvModel\n",
    "from models.basic_qnn import BasicQNN\n",
    "from models.circuit14 import QuantumLayer\n",
    "from models.transfer_learning import CQTransferLearningModel\n",
    "from quantum_circuits.quanv_circuit import create_quanv_circuit\n",
    "from quantum_circuits.basic_qnn_circuit import create_quantum_circuit\n",
    "from quantum_circuits.circuit14_circuit import create_circuit14\n",
    "from quantum_circuits.transfer_learning_circuit import create_transfer_learning_circuit\n",
    "from utils.training import train_model, evaluate_model_with_metrics\n",
    "from utils.visualization import plot_training_history, plot_quanv_visualization, plot_model_comparison\n",
    "from attacks.quantum_leak import CloudLeak, QuantumLeak, HuberLoss\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "def run_quanv_experiment():\n",
    "    pipeline = CIFAR10DataPipeline(n_train=N_TRAIN, n_test=N_TEST, save_path=SAVE_PATH)\n",
    "    train_loader, test_loader = get_cq_dataloaders(pipeline, batch_size=BATCH_SIZE, device=torch.device(DEVICE))\n",
    "    train_images = []\n",
    "    train_labels = []\n",
    "    for images, labels in train_loader:\n",
    "        train_images.append(images.cpu().numpy())\n",
    "        train_labels.append(labels.cpu().numpy())\n",
    "    train_images = np.concatenate(train_images)\n",
    "    train_labels = np.concatenate(train_labels)\n",
    "    test_images = []\n",
    "    test_labels = []\n",
    "    for images, labels in test_loader:\n",
    "        test_images.append(images.cpu().numpy())\n",
    "        test_labels.append(labels.cpu().numpy())\n",
    "    test_images = np.concatenate(test_images)\n",
    "    test_labels = np.concatenate(test_labels)\n",
    "    train_images = train_images.transpose(0, 2, 3, 1)\n",
    "    test_images = test_images.transpose(0, 2, 3, 1)\n",
    "    quanv_circuit = create_quanv_circuit()\n",
    "    q_train_images, q_test_images = pipeline.preprocess_quanv(train_images, test_images, quanv_circuit, load_from_drive=True)\n",
    "    q_train_images = torch.tensor(q_train_images, dtype=torch.float32).clone().detach().permute(0, 3, 1, 2).to(DEVICE)\n",
    "    q_test_images = torch.tensor(q_test_images, dtype=torch.float32).clone().detach().permute(0, 3, 1, 2).to(DEVICE)\n",
    "    train_labels = torch.tensor(train_labels, dtype=torch.float32).clone().detach().view(-1, 1).to(DEVICE)\n",
    "    test_labels = torch.tensor(test_labels, dtype=torch.float32).clone().detach().view(-1, 1).to(DEVICE)\n",
    "    train_dataset = TensorDataset(q_train_images, train_labels)\n",
    "    test_dataset = TensorDataset(q_test_images, test_labels)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, drop_last=True)\n",
    "    model = QuanvModel().to(DEVICE)\n",
    "    criterion = torch.nn.BCELoss()\n",
    "    train_losses, val_accuracies = train_model(model, train_loader, test_loader, torch.device(DEVICE), criterion, N_EPOCHS, LEARNING_RATE, SAVE_PATH + \"/quanv\")\n",
    "    plot_training_history({'train_loss': train_losses, 'test_accuracy': val_accuracies}, SAVE_PATH + \"/quanv\", \"Quanv Training History\")\n",
    "    plot_quanv_visualization(train_images, q_train_images, SAVE_PATH + \"/quanv\")\n",
    "\n",
    "def run_basic_qnn_experiment():\n",
    "    pipeline = CIFAR10DataPipeline(n_train=N_TRAIN, n_test=N_TEST, save_path=SAVE_PATH)\n",
    "    train_loader, test_loader = get_cq_dataloaders(pipeline, batch_size=BATCH_SIZE, device=torch.device(DEVICE))\n",
    "    quantum_circuit = create_quantum_circuit()\n",
    "    model = BasicQNN(N_QUBITS, quantum_circuit).to(DEVICE)\n",
    "    criterion = torch.nn.BCEWithLogitsLoss()\n",
    "    history = train_model(model, train_loader, test_loader, torch.device(DEVICE), criterion, N_EPOCHS, LEARNING_RATE, SAVE_PATH + \"/basic_qnn\")\n",
    "    plot_training_history(history, SAVE_PATH + \"/basic_qnn\"\t, \"Basic QNN Training History\")\n",
    "\n",
    "def run_circuit14_experiment():\n",
    "    pipeline = CIFAR10DataPipeline(n_train=N_TRAIN, n_test=N_TEST, save_path=SAVE_PATH)\n",
    "    train_loader, test_loader = get_cq_dataloaders(pipeline, batch_size=BATCH_SIZE, device=torch.device(DEVICE))\n",
    "    quantum_circuit = create_circuit14()\n",
    "    model = QuantumLayer(N_QUBITS, N_LAYERS, quantum_circuit, QUANTUM_DEVICE).to(DEVICE)\n",
    "    criterion = torch.nn.BCELoss()\n",
    "    train_losses, val_accuracies = train_model(model, train_loader, test_loader, torch.device(DEVICE), criterion, N_EPOCHS, LEARNING_RATE, SAVE_PATH + \"/circuit14\")\n",
    "    plot_training_history({'train_loss': train_losses, 'test_accuracy': val_accuracies}, SAVE_PATH + \"/circuit14\", \"Circuit14 Training History\")\n",
    "\n",
    "def run_transfer_learning_experiment():\n",
    "    pipeline = CIFAR10DataPipeline(n_train=N_LEAK_TRAIN, n_test=N_LEAK_TEST, save_path=SAVE_PATH)\n",
    "    train_loader, test_loader = get_cq_dataloaders(pipeline, batch_size=BATCH_SIZE, device=torch.device(DEVICE))\n",
    "    model = CQTransferLearningModel(N_QUBITS, N_LAYERS).to(DEVICE)\n",
    "    criterion = torch.nn.BCELoss()\n",
    "    train_losses, val_accuracies = train_model(model, train_loader, test_loader, torch.device(DEVICE), criterion, N_EPOCHS, LEARNING_RATE, SAVE_PATH + \"/transfer_learning\")\n",
    "    plot_training_history({'train_loss': train_losses, 'test_accuracy': val_accuracies}, SAVE_PATH + \"/transfer_learning\", \"Transfer Learning Training History\")\n",
    "\n",
    "def run_leak_experiment(model_type=\"basic_qnn\"):\n",
    "    pipeline = CIFAR10DataPipeline(n_train=N_LEAK_TRAIN, n_test=N_LEAK_TEST, save_path=SAVE_PATH)\n",
    "    train_loader, test_loader = get_cq_dataloaders(pipeline, batch_size=LEAK_BATCH_SIZE, device=torch.device(DEVICE))\n",
    "    out_of_domain_loader = create_out_of_domain_loader(pipeline, batch_size=LEAK_BATCH_SIZE, n_samples=3000)\n",
    "    if model_type == \"basic_qnn\":\n",
    "        quantum_circuit = create_quantum_circuit()\n",
    "        victim_model = BasicQNN(N_LEAK_QUBITS, quantum_circuit).to(DEVICE)\n",
    "        victim_model.load_state_dict(torch.load(os.path.join(SAVE_PATH + \"/basic_qnn\", \"best_model.pth\")))\n",
    "    elif model_type == \"circuit14\":\n",
    "        victim_model = QuantumLayer(N_LEAK_QUBITS, N_LEAK_LAYERS, QUANTUM_DEVICE).to(DEVICE)\n",
    "        victim_model.load_state_dict(torch.load(os.path.join(SAVE_PATH + \"/circuit14\", \"best_model.pth\")))\n",
    "    elif model_type == \"transfer_learning\":\n",
    "        victim_model = CQTransferLearningModel(N_LEAK_QUBITS, N_LEAK_LAYERS).to(DEVICE)\n",
    "        victim_model.load_state_dict(torch.load(os.path.join(SAVE_PATH + \"/transfer_learning\", \"best_model.pth\")))\n",
    "    else:\n",
    "        raise ValueError(\"Invalid model type\")\n",
    "    victim_model.eval()\n",
    "    cloud_leak = CloudLeak(\n",
    "        victim_model,\n",
    "        n_qubits=N_LEAK_QUBITS,\n",
    "        query_budget=LEAK_QUERY_BUDGET,\n",
    "        device=DEVICE,\n",
    "        save_path=QUANTUM_LEAK_SAVE_PATH,\n",
    "        circuit_device=QUANTUM_DEVICE\n",
    "    )\n",
    "    quantum_leak = QuantumLeak(\n",
    "        victim_model,\n",
    "        n_qubits=N_LEAK_QUBITS,\n",
    "        query_budget=LEAK_QUERY_BUDGET,\n",
    "        n_committee=LEAK_N_COMMITTEE,\n",
    "        device=DEVICE,\n",
    "        save_path=QUANTUM_LEAK_SAVE_PATH,\n",
    "        circuit_device=QUANTUM_DEVICE\n",
    "    )\n",
    "    query_dataset = cloud_leak.query_victim(train_loader, n_rounds=3)\n",
    "    query_outputs = np.concatenate([item[1][:, 1] for item in query_dataset])\n",
    "    print(f\"Query dataset noise check - Mean probability: {query_outputs.mean():.4f}, Std: {query_outputs.std():.4f}\")\n",
    "    print(\"Training CloudLeak Single-N...\")\n",
    "    single_n_model, single_n_history = cloud_leak.train(\n",
    "        query_dataset, out_of_domain_loader, n_epochs=20, batch_size=LEAK_BATCH_SIZE, architecture='L2', loss_type='nll'\n",
    "    )\n",
    "    single_n_metrics = cloud_leak.evaluate(single_n_model, test_loader)\n",
    "    print(f\"CloudLeak Single-N Metrics: Accuracy: {single_n_metrics['accuracy']:.2f}%, \"\n",
    "          f\"Precision: {single_n_metrics['precision']:.2f}, Recall: {single_n_metrics['recall']:.2f}, F1: {single_n_metrics['f1']:.2f}\")\n",
    "    print(\"Training CloudLeak Single-H...\")\n",
    "    single_h_model, single_h_history = cloud_leak.train(\n",
    "        query_dataset, out_of_domain_loader, n_epochs=20, batch_size=LEAK_BATCH_SIZE, architecture='L2', loss_type='huber'\n",
    "    )\n",
    "    single_h_metrics = cloud_leak.evaluate(single_h_model, test_loader)\n",
    "    print(f\"CloudLeak Single-H Metrics: Accuracy: {single_h_metrics['accuracy']:.2f}%, \"\n",
    "          f\"Precision: {single_h_metrics['precision']:.2f}, Recall: {single_h_metrics['recall']:.2f}, F1: {single_h_metrics['f1']:.2f}\")\n",
    "    print(\"Training QuantumLeak Ens-N...\")\n",
    "    ens_n_models, ens_n_history = quantum_leak.train(\n",
    "        query_dataset, out_of_domain_loader, n_epochs=N_LEAK_EPOCHS, batch_size=LEAK_BATCH_SIZE, architecture='L2', loss_type='nll'\n",
    "    )\n",
    "    ens_n_metrics = quantum_leak.evaluate(test_loader)\n",
    "    print(f\"QuantumLeak Ens-N Metrics: Accuracy: {ens_n_metrics['accuracy']:.2f}%, \"\n",
    "          f\"Precision: {ens_n_metrics['precision']:.2f}, Recall: {ens_n_metrics['recall']:.2f}, F1: {ens_n_metrics['f1']:.2f}\")\n",
    "    print(\"Training QuantumLeak Ens-H...\")\n",
    "    ens_h_models, ens_h_history = quantum_leak.train(\n",
    "        query_dataset, out_of_domain_loader, n_epochs=N_LEAK_EPOCHS, batch_size=LEAK_BATCH_SIZE, architecture='L2', loss_type='huber'\n",
    "    )\n",
    "    ens_h_metrics = quantum_leak.evaluate(test_loader)\n",
    "    print(f\"QuantumLeak Ens-H Metrics: Accuracy: {ens_h_metrics['accuracy']:.2f}%, \"\n",
    "          f\"Precision: {ens_h_metrics['precision']:.2f}, Recall: {ens_h_metrics['recall']:.2f}, F1: {ens_h_metrics['f1']:.2f}\")\n",
    "    victim_criterion = HuberLoss(delta=0.5)\n",
    "    victim_metrics = evaluate_model_with_metrics(victim_model, test_loader, torch.device(DEVICE), victim_criterion)\n",
    "    print(f\"Victim QNN Metrics: Accuracy: {victim_metrics['accuracy']:.2f}%, \"\n",
    "          f\"Precision: {victim_metrics['precision']:.2f}, Recall: {victim_metrics['recall']:.2f}, F1: {victim_metrics['f1']:.2f}\")\n",
    "    table2_data = {\n",
    "        'Scheme': ['Single-N', 'Single-H', 'Ens-N', 'Ens-H'],\n",
    "        'Accuracy': [single_n_metrics['accuracy'], single_h_metrics['accuracy'], ens_n_metrics['accuracy'], ens_h_metrics['accuracy']],\n",
    "        'Precision': [single_n_metrics['precision'], single_h_metrics['precision'], ens_n_metrics['precision'], ens_h_metrics['precision']],\n",
    "        'Recall': [single_n_metrics['recall'], single_h_metrics['recall'], ens_n_metrics['recall'], ens_h_metrics['recall']],\n",
    "        'F1': [single_n_metrics['f1'], single_h_metrics['f1'], ens_n_metrics['f1'], ens_h_metrics['f1']]\n",
    "    }\n",
    "    table2_df = pd.DataFrame(table2_data)\n",
    "    table2_df.to_csv(os.path.join(QUANTUM_LEAK_SAVE_PATH, 'table2.csv'), index=False)\n",
    "    print(\"\\nTable II:\")\n",
    "    print(table2_df)\n",
    "    table3_data = {\n",
    "        'Method': ['CloudLeak', 'QuantumLeak'],\n",
    "        'In-domain Images': [6000, 6000],\n",
    "        'Out-of-domain Images': [512, 0],\n",
    "        'Query Rounds': [3, 3],\n",
    "        'VQC Architecture': ['L2', 'L2']\n",
    "    }\n",
    "    table3_df = pd.DataFrame(table3_data)\n",
    "    table3_df.to_csv(os.path.join(QUANTUM_LEAK_SAVE_PATH, 'table3.csv'), index=False)\n",
    "    print(\"\\nTable III:\")\n",
    "    print(table3_df)\n",
    "    table4_data = {\n",
    "        'Model': ['Victim QNN', 'CloudLeak Single-N', 'CloudLeak Single-H', 'QuantumLeak Ens-N', 'QuantumLeak Ens-H'],\n",
    "        'Accuracy (%)': [victim_metrics['accuracy'], single_n_metrics['accuracy'], single_h_metrics['accuracy'], ens_n_metrics['accuracy'], ens_h_metrics['accuracy']],\n",
    "        'Precision': [victim_metrics['precision'], single_n_metrics['precision'], single_h_metrics['precision'], ens_n_metrics['precision'], ens_h_metrics['precision']],\n",
    "        'Recall': [victim_metrics['recall'], single_n_metrics['recall'], single_h_metrics['recall'], ens_n_metrics['recall'], ens_h_metrics['recall']],\n",
    "        'F1': [victim_metrics['f1'], single_n_metrics['f1'], single_h_metrics['f1'], ens_n_metrics['f1'], ens_h_metrics['f1']],\n",
    "        'Notes': [\n",
    "            'Original model, no query noise',\n",
    "            'Trained with noisy queries (SPAM: 0.54%, 1Q: 0.177%, 2Q: 2.87%, Crosstalk: 20%)',\n",
    "            'Trained with noisy queries, Huber loss',\n",
    "            'Ensemble of 5 models, noisy queries, BCE loss',\n",
    "            'Ensemble of 5 models, noisy queries, Huber loss'\n",
    "        ]\n",
    "    }\n",
    "    table4_df = pd.DataFrame(table4_data)\n",
    "    table4_df.to_csv(os.path.join(QUANTUM_LEAK_SAVE_PATH, 'table4.csv'), index=False)\n",
    "    print(\"\\nTable IV: Comparison of Victim QNN, CloudLeak, and QuantumLeak\")\n",
    "    print(table4_df)\n",
    "    print(\"\\nRunning ablation study for Figure 5, 6, 7, 8...\")\n",
    "    results = quantum_leak.ablation_study(\n",
    "        train_loader, test_loader, out_of_domain_loader,\n",
    "        query_budgets=[1500, 3000, 6000],\n",
    "        architectures=['L1', 'L2', 'L3', 'A1', 'A2'],\n",
    "        committee_numbers=[3, 5, 7],\n",
    "        epochs=N_LEAK_EPOCHS\n",
    "    )\n",
    "    results_df = pd.read_csv(os.path.join(QUANTUM_LEAK_SAVE_PATH, 'ablation_results.csv'))\n",
    "    quantum_leak.plot_ablation_results(results_df)\n",
    "    plot_model_comparison(\n",
    "        [victim_metrics['accuracy'], single_h_metrics['accuracy'], ens_h_metrics['accuracy']],\n",
    "        ['Victim QNN', 'CloudLeak Single-H', 'QuantumLeak Ens-H'],\n",
    "        QUANTUM_LEAK_SAVE_PATH,\n",
    "        f\"{model_type.capitalize()} Model Comparison\"\n",
    "    )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # run_quanv_experiment()\n",
    "    # run_basic_qnn_experiment()\n",
    "    run_circuit14_experiment()\n",
    "    run_transfer_learning_experiment()\n",
    "    # run_leak_experiment(\"basic_qnn\")\n",
    "    # run_leak_experiment(\"circuit14\")\n",
    "    # run_leak_experiment(\"transfer_learning\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6308be77",
   "metadata": {},
   "source": [
    "\n",
    "## 2. Chạy các thử nghiệm\n",
    "\n",
    "Cell dưới đây cho phép bạn chạy các thử nghiệm chính của dự án.\n",
    "Bỏ comment (xóa dấu `#`) ở dòng tương ứng với thử nghiệm bạn muốn chạy.\n",
    "\n",
    "**Lưu ý:**\n",
    "- Một bản vá lỗi cho `QuantumLayer.forward` đã được áp dụng tự động để tránh lỗi `ValueError` khi chuẩn hóa vector.\n",
    "- Bạn có thể chạy lại cell này nhiều lần để thực hiện các thử nghiệm khác nhau mà không cần chạy lại các cell phía trên.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becbf971",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import các hàm từ file main.py vừa được tạo\n",
    "from main import (\n",
    "    run_quanv_experiment,\n",
    "    run_basic_qnn_experiment,\n",
    "    run_circuit14_experiment,\n",
    "    run_transfer_learning_experiment,\n",
    "    run_leak_experiment\n",
    ")\n",
    "\n",
    "# --- BẢN VÁ LỖI TỰ ĐỘNG ---\n",
    "# Áp dụng bản vá cho lỗi ValueError khi chuẩn hóa vector trong QuantumLayer\n",
    "try:\n",
    "    import torch\n",
    "    from models.circuit14 import QuantumLayer\n",
    "\n",
    "    def forward_patched(self, inputs):\n",
    "        x = torch.relu(self.conv(inputs))\n",
    "        x = x.view(-1, 16 * 15 * 15)\n",
    "        x = torch.tanh(self.pre_net(x))\n",
    "        # Chuẩn hóa để tránh lỗi chia cho 0\n",
    "        x = torch.nn.functional.normalize(x, p=2, dim=1, eps=1e-8)\n",
    "        \n",
    "        batch_size = x.size(0)\n",
    "        outputs = []\n",
    "        for i in range(batch_size):\n",
    "            q_out = self.quantum_circuit(x[i], self.weights, self.crx_weights)\n",
    "            q_out = torch.stack(q_out).float()\n",
    "            outputs.append(q_out)\n",
    "        outputs = torch.stack(outputs)\n",
    "        probs = self.fc(outputs).sigmoid()\n",
    "        return probs\n",
    "\n",
    "    QuantumLayer.forward = forward_patched\n",
    "    print(\"✅ Đã áp dụng bản vá cho QuantumLayer.forward để sửa lỗi ValueError.\")\n",
    "except ImportError:\n",
    "    print(\"⚠️ Không tìm thấy QuantumLayer, bỏ qua việc vá lỗi.\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Lỗi khi áp dụng bản vá: {e}\")\n",
    "\n",
    "\n",
    "# --- CHỌN THỬ NGHIỆM ĐỂ CHẠY ---\n",
    "# Bỏ comment (xóa #) ở dòng bạn muốn thực thi.\n",
    "# Chỉ nên chạy một thử nghiệm mỗi lần để dễ theo dõi.\n",
    "\n",
    "print(\"\\n--- Bắt đầu chạy thử nghiệm Circuit14 ---\")\n",
    "run_circuit14_experiment()\n",
    "\n",
    "# print(\"\\n--- Bắt đầu chạy thử nghiệm Transfer Learning ---\")\n",
    "# run_transfer_learning_experiment()\n",
    "\n",
    "# print(\"\\n--- Bắt đầu chạy thử nghiệm Quanv ---\")\n",
    "# run_quanv_experiment()\n",
    "\n",
    "# print(\"\\n--- Bắt đầu chạy thử nghiệm Basic QNN ---\")\n",
    "# run_basic_qnn_experiment()\n",
    "\n",
    "# print(\"\\n--- Bắt đầu chạy thử nghiệm Leak trên Basic QNN ---\")\n",
    "# run_leak_experiment(\"basic_qnn\")\n",
    "\n",
    "# print(\"\\n--- Bắt đầu chạy thử nghiệm Leak trên Circuit14 ---\")\n",
    "# run_leak_experiment(\"circuit14\")\n",
    "\n",
    "# print(\"\\n--- Bắt đầu chạy thử nghiệm Leak trên Transfer Learning ---\")\n",
    "# run_leak_experiment(\"transfer_learning\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
